# Feature Engineering

1. Feature engineering can be broadly classified into following types:
 Dealing with outlier
 
 Filling or Dropping the outlier
 
 Dealing with categorical data
 
 Dropping less feature important columns
 
 2. Numerical encoding or Mapping, one hot encoding techniques are described to handle the categorical string values. The string values needs to be converted to the integer values before feeding it to the machine learning model why beacuse it doesn't make sensse or we can not multiply the numerical coefficient values with string values.
 
 3. Different plotting techniques to idenfying the outlier, different techniques to analyse the least correalted features and removing it, different techniques are explained in details.
 
 4. We always need to fill in or remove the NaN values from the feature. Different techniques to fill the data are explained in this ipynb file. We also analayse when to drop and when to fill in data for a feature.'
 
 
 5. Reference: Python for Machine Learning & Data Science Masterclass (udemy): Jose Portilla
